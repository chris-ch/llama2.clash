cabal-version:  3.4

name:           llama2
version:        0.1.0.0
description:    Please see the README on GitHub at <https://github.com/chris-ch/llama2.clash#readme>
homepage:       https://github.com/chris-ch/llama2.clash#readme
bug-reports:    https://github.com/chris-ch/llama2.clash/issues
author:         Christophe Alexandre
maintainer:     christophe.alexandre@pm.me
category:       LLM
copyright:      2023 Christophe Alexandre
license:        MIT
license-file:   LICENSE
build-type:     Simple
extra-source-files:
    README.md

source-repository head
  type: git
  location: https://github.com/chris-ch/llama2.clash

-- Define flags for model sizes
flag model-260k
  description: Build with MODEL_260K configuration
  default: False
  manual: True

flag model-15m
  description: Build with MODEL_15M configuration
  default: True
  manual: True

-- package-wide defaults
common project-defaults
  default-language: Haskell2010
  default-extensions:
    BangPatterns
    DataKinds
    DeriveAnyClass
    DeriveGeneric
    DoAndIfThenElse
    FlexibleContexts
    GeneralizedNewtypeDeriving
    ImplicitParams
    InstanceSigs
    KindSignatures
    LambdaCase
    MonoLocalBinds
    NamedFieldPuns
    NoImplicitPrelude
    NumericUnderscores
    OverloadedStrings
    RecordWildCards
    ScopedTypeVariables
    TemplateHaskell
    TupleSections
    TypeApplications
    TypeFamilies
    TypeOperators
    UndecidableInstances
  ghc-options:
    -Wall
    -Wcompat
    -Widentities
    -Wincomplete-record-updates
    -Wincomplete-uni-patterns
    -Wmissing-export-lists
    -Wmissing-home-modules
    -Wpartial-fields
    -Wredundant-constraints
    -O2
    -threaded
    -fllvm
    -haddock
    -rtsopts
    -with-rtsopts=-N
  build-depends:
      base
    , binary
    , bytestring
    , clash-prelude
    , clash-lib
    , containers
    , ghc-typelits-knownnat
    , mtl
    , random
    , vector
    , optparse-applicative
    , time

library
  import: project-defaults
  exposed-modules:
    LLaMa2.Decoder.Decoder
    , LLaMa2.Decoder.LayerStack
    , LLaMa2.Decoder.SequenceController
    , LLaMa2.Embedding.InputEmbedding
    , LLaMa2.Embedding.OutputProjection
    , LLaMa2.Layer.Attention.AttentionHead
    , LLaMa2.Layer.Attention.FSM
    , LLaMa2.Layer.Attention.KVCache
    , LLaMa2.Layer.Attention.MultiHeadAttention
    , LLaMa2.Layer.Attention.QKVProjection
    , LLaMa2.Layer.Attention.RotaryEncoding
    , LLaMa2.Layer.FeedForward.FeedForwardNetwork
    , LLaMa2.Layer.FeedForward.Activation
    , LLaMa2.Layer.TransformerLayer
    , LLaMa2.Memory.KVCacheBank
    , LLaMa2.Memory.DualPortRAM
    , LLaMa2.Memory.WeightLoader
    , LLaMa2.Memory.AXI
    , LLaMa2.Memory.AxiReadMaster
    , LLaMa2.Memory.AxiWriteMaster
    , LLaMa2.Memory.FakeAxiSlave
    , LLaMa2.Memory.FileBackedAxiSlave
    , LLaMa2.Memory.SimAxiSlave
    , LLaMa2.Numeric.FixedPoint
    , LLaMa2.Numeric.Quantization
    , LLaMa2.Numeric.Operations
    , LLaMa2.Numeric.Types
    , LLaMa2.ParamsPlaceholder 
    , LLaMa2.Sampling.Distribution
    , LLaMa2.Sampling.Sampler
    , LLaMa2.Top
    , LLaMa2.Types.LayerData
    , LLaMa2.Types.ModelConfig
    , LLaMa2.Types.Parameters
    , Parser
    , Simulation.MatVecSim
    , Tokenizer
  hs-source-dirs:
      project/llama2
  if flag(model-260k)
    ghc-options: -DMODEL_260K
  if flag(model-15m)
    ghc-options: -DMODEL_15M
  if !flag(model-260k) && !flag(model-15m)
    ghc-options: -DMODEL_260K
    buildable: False

executable llama2
  import: project-defaults
  main-is: Main.hs
  hs-source-dirs: project/app
  build-depends: llama2
  if flag(model-260k)
    ghc-options: -DMODEL_260K
  elif flag(model-15m)
    ghc-options: -DMODEL_15M
  else
    ghc-options: -DMODEL_DEFAULT
    buildable: False

test-suite llama2-test
  import: project-defaults
  type: exitcode-stdio-1.0
  main-is: Spec.hs
  other-modules:
      LLaMa2.Layer.Attention.AttentionHeadSpec
      LLaMa2.Layer.Attention.MultiHeadAttentionSpec
      LLaMa2.Layer.FeedForward.FeedForwardNetworkSpec
      LLaMa2.Layer.TransformerLayerSpec
      LLaMa2.Helpers.MatVecI8ESpec 
      LLaMa2.Layer.TransformerLayer.ControlOneHeadSpec
  hs-source-dirs:
      test
  build-depends:
      base
    , clash-prelude
    , hspec
    , llama2
    , QuickCheck
  ghc-options:
    -Wall
    -threaded
    -rtsopts
    -with-rtsopts=-N
    -main-is Spec.main
    -DMODEL_260K
