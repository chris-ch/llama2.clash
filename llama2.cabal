cabal-version:  3.4

name:           llama2
version:        0.1.0.0
description:    Please see the README on GitHub at <https://github.com/chris-ch/llama2.clash#readme>
homepage:       https://github.com/chris-ch/llama2.clash#readme
bug-reports:    https://github.com/chris-ch/llama2.clash/issues
author:         Christophe Alexandre
maintainer:     christophe.alexandre@pm.me
category:       LLM
copyright:      2023 Christophe Alexandre
license:        MIT
license-file:   LICENSE
build-type:     Simple
extra-source-files:
    README.md

source-repository head
  type: git
  location: https://github.com/chris-ch/llama2.clash

-- Define flags for model sizes
flag model-260k
  description: Build with MODEL_260K configuration
  default: False
  manual: True

flag model-15m
  description: Build with MODEL_15M configuration
  default: True
  manual: True

-- package-wide defaults
common project-defaults
  default-language: Haskell2010
  default-extensions:
    BangPatterns
    DataKinds
    DeriveAnyClass
    DeriveGeneric
    DoAndIfThenElse
    FlexibleContexts
    GeneralizedNewtypeDeriving
    ImplicitParams
    InstanceSigs
    KindSignatures
    LambdaCase
    MonoLocalBinds
    NamedFieldPuns
    NoImplicitPrelude
    NumericUnderscores
    OverloadedStrings
    RecordWildCards
    ScopedTypeVariables
    TemplateHaskell
    TupleSections
    TypeApplications
    TypeFamilies
    TypeOperators
    UndecidableInstances
  ghc-options:
    -Wall
    -Wcompat
    -Widentities
    -Wincomplete-record-updates
    -Wincomplete-uni-patterns
    -Wmissing-export-lists
    -Wmissing-home-modules
    -Wpartial-fields
    -Wredundant-constraints
    -O2
    -threaded
    -fllvm
    -haddock
    -rtsopts
    -with-rtsopts=-N
  build-depends:
      base
    , binary
    , bytestring
    , clash-prelude
    , clash-lib
    , containers
    , mtl
    , random
    , vector
    , optparse-applicative
    , time

library
  import: project-defaults
  exposed-modules:
      Helpers
    , Model.Config
    , Model.Core.Embedding
    , Model.Core.PipelineController
    , Model.Core.LayerController
    , Model.Core.StageEnable
    , Model.Core.Transformer
    , Model.Core.Transformer.Internal
    , Model.Core.Types
    , Model.Embedding.PRNG
    , Model.Helpers.EnableWrappers
    , Model.Helpers.FixedPoint
    , Model.Helpers.MatVecI8E
    , Model.Layers.Attention.AttendSequential
    , Model.Layers.Attention.AttentionHead
    , Model.Layers.Attention.MultiHeadAttention
    , Model.Layers.Attention.MultiHeadAttention.Internal
    , Model.Layers.Attention.OnlineSoftmax
    , Model.Layers.Components.Quantized
    , Model.Layers.FeedForward.FeedForwardNetwork
    , Model.Layers.FeedForward.FeedForwardNetwork.Internal
    , Model.Layers.TransformerLayer
    , Model.Memory.KVCacheBank
    , Model.Memory.RamOps
    , Model.Numeric.Types
    , Model.Numeric.Fixed
    , Model.Numeric.ParamPack
    , Model.Top
    , Parser
    , Tokenizer
  hs-source-dirs:
      project/llama2
  if flag(model-260k)
    ghc-options: -DMODEL_260K
  if flag(model-15m)
    ghc-options: -DMODEL_15M
  if !flag(model-260k) && !flag(model-15m)
    ghc-options: -DMODEL_260K
    buildable: False

executable llama2
  import: project-defaults
  main-is: Main.hs
  hs-source-dirs: project/app
  build-depends: llama2
  if flag(model-260k)
    ghc-options: -DMODEL_260K
  elif flag(model-15m)
    ghc-options: -DMODEL_15M
  else
    ghc-options: -DMODEL_DEFAULT
    buildable: False

test-suite llama2-test
  import: project-defaults
  type: exitcode-stdio-1.0
  main-is: Spec.hs
  other-modules:
      Model.Layers.Attention.AttentionHeadSpec
      Model.Layers.Attention.MultiHeadAttentionSpec
      Model.Layers.FeedForward.FeedForwardNetworkSpec
      Model.Layers.TransformerLayerSpec
  hs-source-dirs:
      test
  build-depends:
      base
    , clash-prelude
    , hspec
    , llama2
    , QuickCheck
  ghc-options: -Wall -threaded -rtsopts -with-rtsopts=-N -main-is Spec.mainif flag(model-260k)
    ghc-options: -DMODEL_260K
  if flag(model-15m)
    ghc-options: -DMODEL_15M
  if !flag(model-260k) && !flag(model-15m)
    ghc-options: -DMODEL_DEFAULT
    buildable: False

